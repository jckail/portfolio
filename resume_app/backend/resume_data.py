resume_data = {
    "name": "Jordan Kail",
    "title": "Data Engineer",
    "contact": {
        "phone": "571-218-5000",
        "email": "jckail13@gmail.com",
        "location": "Denver, CO",
        "github": "https://github.com/jckail"
    },
    "experience": [
        {
            "company": "Prove Identity",
            "title": "Staff Data Engineer",
            "date": "06/2023 - Present",
            "location": "Denver, CO",
            "highlights": [
                "Leading company-wide core product refactor from on-prem Java + Oracle to cloud GO + Postgres, cutting response time to 120 ms and opex by 95%.",
                "Developed AI-powered Retrieval-Augmented Generation (RAG) pipelines using LangChain and OpenAI, enabling ad-hoc analytics on product usage and automating 150 human-hours per week.",
                "Implemented an event-driven data streaming platform using Go and Kafka, migrating over 1,000 batch jobs to real-time processing, resulting in significant operational efficiencies and data availability improvements."
            ]
        },
                {
            "company": "Prove Identity",
            "title": "Staff Data Engineer",
            "date": "06/2023 - Present",
            "location": "Denver, CO",
            "highlights": [
                "Leading company-wide core product refactor from on-prem Java + Oracle to cloud GO + Postgres, cutting response time to 120 ms and opex by 95%.",
                "Developed AI-powered Retrieval-Augmented Generation (RAG) pipelines using LangChain and OpenAI, enabling ad-hoc analytics on product usage and automating 150 human-hours per week.",
                "Implemented an event-driven data streaming platform using Go and Kafka, migrating over 1,000 batch jobs to real-time processing, resulting in significant operational efficiencies and data availability improvements."
            ]
        },
                        {
            "company": "Prove Identity",
            "title": "Staff Data Engineer",
            "date": "06/2023 - Present",
            "location": "Denver, CO",
            "highlights": [
                "Leading company-wide core product refactor from on-prem Java + Oracle to cloud GO + Postgres, cutting response time to 120 ms and opex by 95%.",
                "Developed AI-powered Retrieval-Augmented Generation (RAG) pipelines using LangChain and OpenAI, enabling ad-hoc analytics on product usage and automating 150 human-hours per week.",
                "Implemented an event-driven data streaming platform using Go and Kafka, migrating over 1,000 batch jobs to real-time processing, resulting in significant operational efficiencies and data availability improvements."
            ]
        },
                        {
            "company": "Prove Identity",
            "title": "Staff Data Engineer",
            "date": "06/2023 - Present",
            "location": "Denver, CO",
            "highlights": [
                "Leading company-wide core product refactor from on-prem Java + Oracle to cloud GO + Postgres, cutting response time to 120 ms and opex by 95%.",
                "Developed AI-powered Retrieval-Augmented Generation (RAG) pipelines using LangChain and OpenAI, enabling ad-hoc analytics on product usage and automating 150 human-hours per week.",
                "Implemented an event-driven data streaming platform using Go and Kafka, migrating over 1,000 batch jobs to real-time processing, resulting in significant operational efficiencies and data availability improvements."
            ]
        },
                        {
            "company": "Prove Identity",
            "title": "Staff Data Engineer",
            "date": "06/2023 - Present",
            "location": "Denver, CO",
            "highlights": [
                "Leading company-wide core product refactor from on-prem Java + Oracle to cloud GO + Postgres, cutting response time to 120 ms and opex by 95%.",
                "Developed AI-powered Retrieval-Augmented Generation (RAG) pipelines using LangChain and OpenAI, enabling ad-hoc analytics on product usage and automating 150 human-hours per week.",
                "Implemented an event-driven data streaming platform using Go and Kafka, migrating over 1,000 batch jobs to real-time processing, resulting in significant operational efficiencies and data availability improvements."
            ]
        },
        # Add other experience entries here
    ],
    "skills": {
        "Programming": ["Python", "SQL", "GO", "JavaScript", "Rust", "PHP", "Java", "Scala"],
        "Big Data": ["Airflow", "Kafka", "Spark", "ProtoBuff", "Flink", "DBT", "Snowflake", "Databricks", "Iceberg", "Delta Lake", "Neo4J", "Redis", "MongoDB", "PostgreSQL", "Tableau", "ReDash", "Streamlit"],
        "AI & ML": ["OpenAI", "LangChain", "Llama.cpp", "Ollama", "Llama Index", "Pytorch", "TensorFlow", "Hugging Face", "Vector Databases", "Embeddings", "Agents", "CuPy", "Keras", "Caffe", "Scikit-Learn"],
        # Add other skill categories here
    },
    "achievements": [
        {
            "title": "TechCrunch - \"Join Group via QR\"",
            "description": "Pitched, designed and implemented the functionality to enable Facebook group admins to invite users to their groups by generating a QR Code. Used by millions of users daily."
        },
        # Add other achievements here
    ]
}