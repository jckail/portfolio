resume_data = {
    "name": "Jordan Kail",
    "title": "Data Engineer",
    "contact": {
        "email": "jckail13@gmail.com",
        "phone": "571-218-5000",
        "website": "https://jordan-kail.com/",
        "location": "Denver, CO - Open to relocation",
        "github": "https://github.com/jckail",
    },
    "About Me": """I'm a self-proclaimed data geek with an insatiable curiosity for all things tech. When I'm not knee-deep in building data pipelines or experimenting with the latest machine learning models, you can find me outdoors—whether it's snowboarding down a mountain, hiking through the Rockies, camping under the stars, or exploring new craft breweries. I love traveling and discovering new places (and beers!) to fuel my adventurous side.

    I’ve always been passionate about computers and technology, from geeking out over the newest GPUs to tinkering with home labs and DIY tech experiments. This constant drive to learn, innovate, and problem-solve is what excites me about being a Data Engineer. Every day is a new puzzle, and I get to build and optimize systems that have real-world impact. Whether it’s cutting-edge AI projects or cloud infrastructure, I’m always eager to push boundaries and dive into new challenges.""",
    "experience": [
        {
            "company": "Prove Identity",
            "title": "Staff Data Engineer",
            "date": "06/2023 - Ongoing",
            "location": "Denver, CO",
            "highlights": [
                "Leading company-wide core product refactor from on-prem Java + Oracle to cloud GO + Postgres, cutting response time to 120ms and opex by 95%.",
                "Developed AI-powered Retrieval-Augmented Generation (RAG) pipelines using LangChain and OpenAI, enabling ad-hoc analytics on product usage and automating 150 human-hours per week.",
                "Implemented an event-driven data streaming platform using Go and Kafka, migrating over 1,000 batch jobs to real-time processing, resulting in significant operational efficiencies and data availability improvements.",
            ],
        },
        {
            "company": "Meta (Facebook)",
            "title": "Senior Data Engineer",
            "date": "01/2021 - 09/2022",
            "location": "Seattle, WA + Menlo Park, CA + Remote, USA",
            "highlights": [
                "Lead Data Engineer for Facebook Public Groups and Community Chats, managing 10 individual contributors and mentoring 5 others, including interns and junior engineers.",
                "Built ML pipelines and Transformer models in PyTorch for NLP, machine vision, and user segmentation, driving ads, feeds, features, and notifications for billions of users.",
                "Created a framework to programmatically generate thousands of data pipelines, boosting compute efficiency by 66%.",
                "Re-architected petabyte-scale data models, cutting storage costs by 25%.",
            ],
        },
        {
            "company": "Deloitte",
            "title": "Consultant - AI & Advanced Analytics",
            "date": "12/2018 - 12/2020",
            "location": "Atlanta, GA + Menlo Park, CA",
            "highlights": [
                "Automated approximately 31% of human processed healthcare claims using transformer machine learning models, saving 250,000+ hours annually.",
                "Optimized exabyte scale video reliability metrics calculation reducing daily run time by 90% while increasing the scope of metrics calculated.",
                "Led 20+ consultants across multiple Fortune 50 engagements, translating client needs into concrete requirements and ensuring timely delivery of technical products.",
            ],
        },
        {
            "company": "Wide Open West",
            "title": "Data Scientist",
            "date": "11/2017 - 12/2018",
            "location": "Denver, CO",
            "highlights": [
                "Developed ML web applications, increasing field service upgrades by 22% YoY by leveraging custom classification and churn propensity models.",
                "Managed a team of 5 data practitioners, supporting business intelligence and data insights for sales, product, and engineering teams across the company.",
            ],
        },
        {
            "company": "Catholic Health Initiatives",
            "title": "Data Engineer - Business Intelligence",
            "date": "09/2016 - 11/2017",
            "location": "Denver, CO",
            "highlights": [
                "Redesigned rest APIs and data lakes, reducing data processing time for external partner data products from 7 days to 5 minutes."
            ],
        },
        {
            "company": "AcuStream (Acquired by R1 RCM)",
            "title": "Software Engineer - Data",
            "date": "04/2013 - 09/2016",
            "location": "Boulder, CO",
            "highlights": [
                "Built a custom invoicing system, driving $300M+ in annual recurring revenue using a combination of rule-based algorithms and machine learning (KNN)."
            ],
        },
    ],
    "skills": {
        "Programming": [
            "Python",
            "SQL",
            "GO",
            "JavaScript",
            "Rust",
            "PHP",
            "Java",
            "Scala",
        ],
        "Big Data": [
            "Airflow",
            "Kafka",
            "Spark",
            "ProtoBuff",
            "Flink",
            "DBT",
            "Snowflake",
            "Databricks",
            "Iceberg",
            "Delta Lake",
            "Neo4J",
            "Redis",
            "MongoDB",
            "PostgreSQL",
            "Tableau",
            "ReDash",
            "Streamlit",
        ],
        "AI & ML": [
            "OpenAI",
            "LangChain",
            "Llama.cpp",
            "Ollama",
            "Llama Index",
            "Pytorch",
            "TensorFlow",
            "Hugging Face",
            "Vector Databases",
            "Embeddings",
            "Agents",
            "CuPy",
            "Keras",
            "Caffe",
            "Scikit-Learn",
        ],
        "Amazon Web Services (AWS)": [
            "EMR",
            "SageMaker",
            "S3",
            "Redshift",
            "Glue",
            "MWAA",
            "RDS",
            "Kinesis",
            "Firehose",
            "DynamoDB",
            "Bedrock",
            "SNS",
        ],
        "Google Cloud Platform (GCP)": [
            "BigQuery",
            "Compute Engine",
            "Dataflow",
            "AutoML",
            "Vertex AI Studio",
            "PubSub",
            "Cloud Run",
            "Looker",
            "Firebase",
        ],
        "Web Development": [
            "Docker",
            "Kubernetes",
            "FastAPI",
            "Flask",
            "Django",
            "Svelte",
            "React",
            "Node.js",
            "HTML",
            "GraphQL",
            "Gin",
            "Retool",
        ],
    },
    "achievements": [
        {
            "title": 'TechCrunch - "Join Group via QR"',
            "description": "Pitched, designed and implemented the functionality to enable Facebook group admins to invite users to their groups by generating a QR Code. Used by millions of users daily.",
            "link": "https://techcrunch.com/2022/03/09/facebook-rolls-out-new-tools-for-group-admins-to-manage-their-communities-and-reduce-misinformation/",
        },
        {
            "title": "Jobbr - AI Agent Job Matching",
            "description": "Created a custom AI agent that matches a resume to available jobs at tech companies. Using Python, Langchain, FastAPI and OpenAI.",
            "link": "https://github.com/jckail/Jobbr",
        },
        {
            "title": 'Developed "pointup.io"',
            "description": 'An AI web app for "All of your loyalty points in one place," powered by a Selenium-WebDriver agent in AWS via elastic beanstalk, lambda, and s3. ',
            "link": "https://www.pointup.io/ https://github.com/jckail/point_bot",
        },
        {
            "title": "Algorithmic Crypto Trading Project",
            "description": "Created crypto trading algorithm via scraped crypto, NASDAQ, and CPME rare minerals data. On AWS Sage maker via BOTO3, Django, pandas, and beautiful soup.",
            "link": "https://github.com/jckail/crypto_trader",
        },
        {
            "title": "goPilot",
            "description": "CLI tool to help build applications written in GO.",
            "link": "https://github.com/jckail/goPilot",
        },
    ],
}
